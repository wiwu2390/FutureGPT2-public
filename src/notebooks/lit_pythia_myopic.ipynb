{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbf9da59-adc3-41e7-81df-af854ec8c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/workspace/cache/huggingface/'\n",
    "os.chdir('/workspace/FutureGPT2/src/')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from torch import optim, nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "import wandb\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "import transformers\n",
    "from inspect import signature, _ParameterKind\n",
    "import copy\n",
    "import gc\n",
    "import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import islice\n",
    "from copy import deepcopy\n",
    "\n",
    "from models.myopic_model import *\n",
    "from models.gpt_model import *\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3751427-cb5b-4cab-908f-55b914114d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "   torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55659a78-bcbf-4978-a901-56790bd447ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/wwu/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key='os.environ[WANDB_API_KEY]', relogin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f309f9b-df86-46a5-af76-4e7968dfdf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/EleutherAI/pythia\n",
    "LR_DICT = {\n",
    "    #'14m':  1.0e-3,\n",
    "    '70m':  1.0e-3,\n",
    "    '160m': 6.0e-4,\n",
    "    '410m': 3.0e-4,\n",
    "    '1b':   3.0e-4,\n",
    "    '1.4b': 2.0e-4,\n",
    "    '2.8b': 1.6e-4,\n",
    "    '6.9b': 1.2e-4,\n",
    "    '12b':  1.2e-4,\n",
    "}\n",
    "\n",
    "model_size = '70m'\n",
    "params = {\n",
    "    'model_name': f'EleutherAI/pythia-{model_size}-deduped',\n",
    "    'lr': LR_DICT[model_size]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2fde467-b571-4cc0-8eda-c6313ddc4cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5M examples sampled from the-pile. truncated to len 64\n",
    "train = load_dataset(\n",
    "    'EleutherAI/pile-deduped-pythia-random-sampled', \n",
    "    split='train'\n",
    ")\n",
    "train = train.rename_column('Tokens', 'input_ids')\n",
    "train = train.remove_columns([c for c in train.column_names if c != 'input_ids'])\n",
    "train = train.cast_column('input_ids', datasets.Sequence(datasets.Value('int64')))\n",
    "train = train.with_format('torch')\n",
    "train_loader = DataLoader(train, batch_size=32)#, num_workers=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b624a4b6-91d3-403c-b0f6-5bd1ffe8ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = '_'.join(\n",
    "    [f'PYTHIA-MYOPIC'] + \n",
    "    [f'{k}-{v}' for k, v in {**params}.items()]\n",
    ").replace('EleutherAI/', '')\n",
    "PROJ = 'LAISR_FUTURE_PYTHIA'\n",
    "wandb_logger = WandbLogger(\n",
    "    name=NAME,\n",
    "    project=PROJ,\n",
    "    log_model=False,   # Only save checkpoints locally\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e2009aa-4900-480c-899d-e3cd1bedacbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "lr_monitor = LearningRateMonitor()\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"/workspace/checkpoints\",\n",
    "    filename=NAME + \"_{global_step}_{val_loss:.2f}\",\n",
    "    every_n_epochs=1,\n",
    "    save_top_k=1,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    divergence_threshold=15,\n",
    "    min_delta=0.00,\n",
    "    patience=10,\n",
    "    verbose=False,\n",
    "    mode='min',\n",
    ")\n",
    "trainer = L.Trainer(\n",
    "    fast_dev_run=False,\n",
    "    logger=wandb_logger,\n",
    "    #val_check_interval=.1,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback, lr_monitor],\n",
    "    max_epochs=1,\n",
    "    enable_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "241ad496-1e0c-416e-b59b-1b5b25d6c0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "myopic_model = AutoModelForCausalLM.from_pretrained(params['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56c2c6e2-7175-4a63-b6e1-ee5fb64489c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wwu/.local/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'myopic_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['myopic_model'])`.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwilswu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240409_004248-s80m0dsd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wilswu/LAISR_FUTURE_PYTHIA/runs/s80m0dsd' target=\"_blank\">PYTHIA-VANILLA_model_name-pythia-70m-deduped_lr-0.001</a></strong> to <a href='https://wandb.ai/wilswu/LAISR_FUTURE_PYTHIA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wilswu/LAISR_FUTURE_PYTHIA' target=\"_blank\">https://wandb.ai/wilswu/LAISR_FUTURE_PYTHIA</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wilswu/LAISR_FUTURE_PYTHIA/runs/s80m0dsd' target=\"_blank\">https://wandb.ai/wilswu/LAISR_FUTURE_PYTHIA/runs/s80m0dsd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LitMyopicModel(\n",
    "    myopic_model=myopic_model,\n",
    "    orig_model=None,    # set to None (default) for cutgrad training [use own detached hidden state or kv]\n",
    "    loss_type='myopic_loss',\n",
    "    to_myopic=to_myopic_neox,\n",
    "    from_kv=False,\n",
    "    layer_past = [None for _ in range(len(myopic_model.gpt_neox.layers))]\n",
    ")\n",
    "wandb_logger.watch(model.myopic_model, log='all', log_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "340c982a-8565-4248-8ca3-781f96c00506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wwu/.local/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:43: attribute 'to_myopic' removed from hparams because it cannot be pickled\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name         | Type               | Params\n",
      "----------------------------------------------------\n",
      "0 | myopic_model | GPTNeoXForCausalLM | 70.4 M\n",
      "----------------------------------------------------\n",
      "70.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "70.4 M    Total params\n",
      "281.706   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM TRAINING STEPS 9766\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de5e0eb2964542c88139c3ce6381cf5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3080e077-2c57-4ca9-b0c1-eef7fe2ee294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
