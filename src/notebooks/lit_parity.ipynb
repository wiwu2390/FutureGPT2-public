{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c2786d-c353-4e0e-8e52-756ace693378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/workspace/cache/huggingface/'\n",
    "os.chdir('/workspace/FutureGPT2/src/')\n",
    "\n",
    "import numpy as np\n",
    "from torch import optim, nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "import wandb\n",
    "from transformers import GPT2Config, GPT2Model, AutoTokenizer\n",
    "import transformers\n",
    "import lightning as L\n",
    "from inspect import signature, _ParameterKind\n",
    "import copy\n",
    "import gc\n",
    "import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import repeat\n",
    "\n",
    "from models.gpt_model import *\n",
    "from models.myopic_model import to_myopic_gpt2\n",
    "from data.parity import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a37d589-2971-425c-8aee-28c57054ab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "    torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aaeae7e-02f8-4e3c-a811-0414d9088157",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "Token = {v: k for k, v in tokenizer.get_vocab().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a5f679c-0108-4fc1-8b5d-f5de721d26e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN=30\n",
    "train = DataLoader(\n",
    "    ParityDataset(\n",
    "        size=1_000_000, \n",
    "        seq_len=SEQ_LEN,\n",
    "        tokenizer=tokenizer,\n",
    "    ), \n",
    "    batch_size=512,\n",
    "    #num_workers=95,\n",
    ")\n",
    "val = DataLoader(\n",
    "    ParityDataset(\n",
    "        size=10_000, \n",
    "        seq_len=SEQ_LEN,\n",
    "        tokenizer=tokenizer,\n",
    "    ), \n",
    "    batch_size=512,\n",
    "    #num_workers=95,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5c92b9d-6703-4b92-801c-94a614914126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/wwu/.netrc\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwilswu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240506_210109-03mi4tmx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wilswu/LAISR_FUTURE_PARITY/runs/03mi4tmx' target=\"_blank\">PARITY_GPT2_SEQLEN_30</a></strong> to <a href='https://wandb.ai/wilswu/LAISR_FUTURE_PARITY' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wilswu/LAISR_FUTURE_PARITY' target=\"_blank\">https://wandb.ai/wilswu/LAISR_FUTURE_PARITY</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wilswu/LAISR_FUTURE_PARITY/runs/03mi4tmx' target=\"_blank\">https://wandb.ai/wilswu/LAISR_FUTURE_PARITY/runs/03mi4tmx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "/home/wwu/.local/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory /workspace/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/home/wwu/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "\n",
      "  | Name         | Type            | Params\n",
      "-------------------------------------------------\n",
      "0 | model        | GPT2LMHeadModel | 124 M \n",
      "  | other params | n/a             | 31    \n",
      "-------------------------------------------------\n",
      "124 M     Trainable params\n",
      "31        Non-trainable params\n",
      "124 M     Total params\n",
      "497.759   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM TRAINING STEPS 1954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wwu/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92cfcabd7559443ba29dc7eb85836ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "wandb.login(key='os.environ[WANDB_API_KEY]', relogin=True)\n",
    "NAME = f'PARITY_GPT2_SEQLEN_{SEQ_LEN}'\n",
    "PROJ = 'LAISR_FUTURE_PARITY'\n",
    "wandb_logger = WandbLogger(\n",
    "    name=NAME,\n",
    "    project=PROJ,\n",
    "    log_model=False,   # Only save checkpoints locally\n",
    ")\n",
    "lr_monitor = LearningRateMonitor()\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"/workspace/checkpoints\",\n",
    "    filename=NAME + \"_{global_step}_{train_loss:.2f}\",\n",
    "    every_n_epochs=1,\n",
    "    save_top_k=1,\n",
    "    monitor='train_loss',\n",
    "    mode='min',\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='train_loss',\n",
    "    divergence_threshold=10000,\n",
    "    min_delta=0.00,\n",
    "    patience=100000,\n",
    "    verbose=False,\n",
    "    mode='min',\n",
    ")\n",
    "trainer = L.Trainer(\n",
    "    fast_dev_run=False,\n",
    "    logger=wandb_logger,\n",
    "    val_check_interval=0.1,\n",
    "    #check_val_every_n_epoch=5,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback, lr_monitor],\n",
    "    max_epochs=1,\n",
    "    enable_progress_bar=True,\n",
    ")\n",
    "model = LitGPTModel(\n",
    "    pretrain=False,\n",
    "    loss_mask=[0]*SEQ_LEN + [1],\n",
    "    acc_cutoff=SEQ_LEN+1,\n",
    ")\n",
    "wandb_logger.watch(model.model, log='all')\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=train,\n",
    "    val_dataloaders=val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "120c5465-7468-4c75-8f37-6f5dcde6cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb9db14-c41f-432e-9041-b0eb3daea0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
